{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13e7f7ab",
   "metadata": {},
   "source": [
    "1) Requirements Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94799fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy.stats import binomtest as binom_test\n",
    "#\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from scipy.stats import t\n",
    "import os\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37838d35",
   "metadata": {},
   "source": [
    "2) Getting the relevant data from the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e0fed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the data from ELia's dataset \n",
    "# paths \n",
    "\n",
    "Root_dir = \"..\"\n",
    "Data_dir = os.path.join(Root_dir, \"data_extraction\", \"raw_df\")\n",
    "\n",
    "# load the CSV + computing the log returns\n",
    "def load_with_log_returns(csv_filename,lag = 1):\n",
    "\t\"\"\"\n",
    "\tLoad a CSV from the Data_dir and compute log returns and also the Log Prices  on the 'Close' column.\n",
    "\tThis function is robust: it will handle CSVs that have either 'Date' or 'Datetime' (or both).\n",
    "\tIt raises a clear error if neither date column or the 'Close' column is present.\n",
    "\t\"\"\"\n",
    "\tpath = os.path.join(Data_dir, csv_filename)\n",
    "\t# Read first without forcing parse_dates so we can detect which date columns exist\n",
    "\tdf = pd.read_csv(path)\n",
    "\t# Parse available date columns robustly\n",
    "\tfor col in ['Date', 'Datetime']:\n",
    "\t\tif col in df.columns:\n",
    "\t\t\tdf[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\t# Prefer 'Date' as the index, otherwise use 'Datetime' if present\n",
    "\tif 'Date' in df.columns and not df['Date'].isna().all():\n",
    "\t\tdf.set_index('Date', inplace=True)\n",
    "\telif 'Datetime' in df.columns and not df['Datetime'].isna().all():\n",
    "\t\tdf.set_index('Datetime', inplace=True)\n",
    "\telse:\n",
    "\t\traise ValueError(f\"CSV {path} must contain a 'Date' or 'Datetime' column. Found: {list(df.columns)}\")\n",
    "\t# Ensure 'Close' exists\n",
    "\tif 'Close' not in df.columns:\n",
    "\t\traise ValueError(f\"CSV {path} must contain a 'Close' column. Found: {list(df.columns)}\")\n",
    "\t# Compute log returns safely (first entry will be NaN)\n",
    "\tdf['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(lag))\n",
    "\t\n",
    "\tdf['Log_Prices'] = np.log(df['Close'])\n",
    "\treturn df\n",
    "\n",
    "\n",
    "nasdaq_daily_df = load_with_log_returns('nasdaq_daily_df.csv')\n",
    "nasdaq_weekly_df = load_with_log_returns('nasdaq_weekly_df.csv')\n",
    "nasdaq_monthly_df = load_with_log_returns('nasdaq_monthly_df.csv')\n",
    "nasdaq_hourly_df = load_with_log_returns('nasdaq_hourly_df.csv')\n",
    "\n",
    "# The DataFrame uses 'Date' (or 'Datetime') as the index, so select the 'Log_Returns' column directly.\n",
    "nasdaq_daily_log_returns = nasdaq_daily_df['Log_Returns'].dropna()\n",
    "nasdaq_weekly_log_returns = nasdaq_weekly_df['Log_Returns'].dropna()\n",
    "nasdaq_monthly_log_returns = nasdaq_monthly_df['Log_Returns'].dropna()\n",
    "nasdaq_hourly_df_log_returns = nasdaq_hourly_df['Log_Returns'].dropna()\n",
    "\n",
    "nasdaq_hourly_df_log_prices = nasdaq_hourly_df['Log_Prices'].dropna()\n",
    "nasdaq_daily_df_log_prices = nasdaq_daily_df['Log_Prices'].dropna()\n",
    "nasdaq_weekly_df_log_prices = nasdaq_weekly_df['Log_Prices'].dropna()\n",
    "nasdaq_monthly_df_log_prices = nasdaq_monthly_df['Log_Prices'].dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b1afd3",
   "metadata": {},
   "source": [
    "3) Testing the Martingale Properties of the Log Return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbc53748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "TEST – NASDAQ – DAILY log returns\n",
      "==============================\n",
      "Number of obs:                    9035\n",
      "Mean return:                      4.326745e-04\n",
      "Std dev:                          1.458158e-02\n",
      "Std error of mean:                1.534053e-04\n",
      "t-statistic:                      2.820\n",
      "\n",
      "Two-sided p-value (H1: mean ≠ 0): 0.004806\n",
      "One-sided p-value (H1: mean < 0 → supermartingale): 0.9976\n",
      "One-sided p-value (H1: mean > 0 → submartingale):   0.002403\n",
      "\n",
      "Interpretation:\n",
      "→ Significant *positive* drift: SUBMARTINGALE behaviour.\n",
      "\n",
      "==============================\n",
      "TEST – NASDAQ – WEEKLY log returns\n",
      "==============================\n",
      "Number of obs:                    1871\n",
      "Mean return:                      2.090653e-03\n",
      "Std dev:                          3.037720e-02\n",
      "Std error of mean:                7.022808e-04\n",
      "t-statistic:                      2.977\n",
      "\n",
      "Two-sided p-value (H1: mean ≠ 0): 0.002949\n",
      "One-sided p-value (H1: mean < 0 → supermartingale): 0.9985\n",
      "One-sided p-value (H1: mean > 0 → submartingale):   0.001474\n",
      "\n",
      "Interpretation:\n",
      "→ Significant *positive* drift: SUBMARTINGALE behaviour.\n",
      "\n",
      "==============================\n",
      "TEST – NASDAQ – MONTHLY log returns\n",
      "==============================\n",
      "Number of obs:                    430\n",
      "Mean return:                      9.274598e-03\n",
      "Std dev:                          6.224405e-02\n",
      "Std error of mean:                3.001674e-03\n",
      "t-statistic:                      3.090\n",
      "\n",
      "Two-sided p-value (H1: mean ≠ 0): 0.002133\n",
      "One-sided p-value (H1: mean < 0 → supermartingale): 0.9989\n",
      "One-sided p-value (H1: mean > 0 → submartingale):   0.001067\n",
      "\n",
      "Interpretation:\n",
      "→ Significant *positive* drift: SUBMARTINGALE behaviour.\n",
      "\n",
      "==============================\n",
      "TEST – NASDAQ – HOURLY log returns\n",
      "==============================\n",
      "Number of obs:                    1528\n",
      "Mean return:                      1.090307e-04\n",
      "Std dev:                          5.671343e-03\n",
      "Std error of mean:                1.450856e-04\n",
      "t-statistic:                      0.751\n",
      "\n",
      "Two-sided p-value (H1: mean ≠ 0): 0.4525\n",
      "One-sided p-value (H1: mean < 0 → supermartingale): 0.7738\n",
      "One-sided p-value (H1: mean > 0 → submartingale):   0.2262\n",
      "\n",
      "Interpretation:\n",
      "→ Mean return not significantly different from zero: MARTINGALE-compatible.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_mean_returns(returns):\n",
    "    \"\"\"\n",
    "    Basically a variant of the T-test where we test if the mean return is equal to zero for each respective frequency.\n",
    "\n",
    "    Returns:\n",
    "        (mean_return, std_return, se_return, t_stat, p_value_super, p_value_sub, p_value_two)\n",
    "\n",
    "    p_value_super: one-sided p-value for H1: mean < 0 (supermartingale)\n",
    "    p_value_sub:   one-sided p-value for H1: mean > 0 (submartingale)\n",
    "    p_value_two:   two-sided p-value for H1: mean != 0\n",
    "    \"\"\"\n",
    "    # converts it all to a big ol numpy and drops the NaNs\n",
    "    r = returns.values if hasattr(returns, \"values\") else np.array(returns)\n",
    "    r = np.asarray(r)\n",
    "    r = r[~np.isnan(r)]\n",
    "\n",
    "    n = len(r)\n",
    "    if n < 2:\n",
    "        raise ValueError(\"Not enough data points to perform the test.\")\n",
    "\n",
    "    mean_return = np.mean(r)\n",
    "    std_return = np.std(r, ddof=1)\n",
    "    se_return = std_return / np.sqrt(n)\n",
    "\n",
    "    # handle zero-variance case --> it just a likkle safety net \n",
    "    if se_return == 0:\n",
    "        t_stat = 0.0\n",
    "    else:\n",
    "        t_stat = mean_return / se_return\n",
    "\n",
    "    # one-sided p-values \n",
    "    p_value_super = t.cdf(t_stat, df=n-1)   \n",
    "    p_value_sub = 1 - p_value_super        \n",
    "    p_value_two = 2 * min(p_value_super, p_value_sub)  \n",
    "\n",
    "    return mean_return, std_return, se_return, t_stat, p_value_super, p_value_sub, p_value_two\n",
    "\n",
    "def print_mean_return_results(returns, label=\"Mean Return\"):\n",
    "    (mean, std, se, t_stat,\n",
    "     p_super, p_sub, p_two) = test_mean_returns(returns)\n",
    "\n",
    "    n = len(returns)\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"TEST – {label}\")\n",
    "    print(\"==============================\")\n",
    "    print(f\"Number of obs:                    {n}\")\n",
    "    print(f\"Mean return:                      {mean:.6e}\")\n",
    "    print(f\"Std dev:                          {std:.6e}\")\n",
    "    print(f\"Std error of mean:                {se:.6e}\")\n",
    "    print(f\"t-statistic:                      {t_stat:.3f}\")\n",
    "    print(f\"\\nTwo-sided p-value (H1: mean ≠ 0): {p_two:.4g}\")\n",
    "    print(f\"One-sided p-value (H1: mean < 0 → supermartingale): {p_super:.4g}\")\n",
    "    print(f\"One-sided p-value (H1: mean > 0 → submartingale):   {p_sub:.4g}\")\n",
    "\n",
    "    # Interpretation\n",
    "    print(\"\\nInterpretation:\")\n",
    "    if p_two < 0.05:\n",
    "        if mean > 0:\n",
    "            print(\"→ Significant *positive* drift: SUBMARTINGALE behaviour.\")\n",
    "        else:\n",
    "            print(\"→ Significant *negative* drift: SUPERMARTINGALE behaviour.\")\n",
    "    else:\n",
    "        print(\"→ Mean return not significantly different from zero: MARTINGALE-compatible.\")\n",
    "\n",
    "print_mean_return_results(nasdaq_daily_log_returns,   \"NASDAQ – DAILY log returns\")\n",
    "print_mean_return_results(nasdaq_weekly_log_returns,  \"NASDAQ – WEEKLY log returns\")\n",
    "print_mean_return_results(nasdaq_monthly_log_returns, \"NASDAQ – MONTHLY log returns\")\n",
    "print_mean_return_results(nasdaq_hourly_df_log_returns, \"NASDAQ – HOURLY log returns\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6fc1b4",
   "metadata": {},
   "source": [
    "4.1 CW ratio for the log returns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37692917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Cowles & Jones Test (Daily log returns) =====\n",
      "N_S (sequences, same sign) : 4696\n",
      "N_R (reversals, opp. sign) : 4332\n",
      "Total pairs N              : 9028\n",
      "CĴ = N_S / N_R            : 1.0840\n",
      "p̂ = N_S / (N_S+N_R)       : 0.5202\n",
      "z-stat (H0: p = 0.5)       : 3.8309\n",
      "p-value (two-sided)        : 0.000128\n",
      "→ Reject RW1 (μ=0) at 5% level.\n",
      "\n",
      "===== Cowles & Jones Test (Hourly log returns) =====\n",
      "N_S (sequences, same sign) : 761\n",
      "N_R (reversals, opp. sign) : 766\n",
      "Total pairs N              : 1527\n",
      "CĴ = N_S / N_R            : 0.9935\n",
      "p̂ = N_S / (N_S+N_R)       : 0.4984\n",
      "z-stat (H0: p = 0.5)       : -0.1280\n",
      "p-value (two-sided)        : 0.898186\n",
      "→ Cannot reject RW1 (μ=0) at 5% level.\n",
      "\n",
      "===== Cowles & Jones Test (Weekly log returns) =====\n",
      "N_S (sequences, same sign) : 967\n",
      "N_R (reversals, opp. sign) : 902\n",
      "Total pairs N              : 1869\n",
      "CĴ = N_S / N_R            : 1.0721\n",
      "p̂ = N_S / (N_S+N_R)       : 0.5174\n",
      "z-stat (H0: p = 0.5)       : 1.5035\n",
      "p-value (two-sided)        : 0.132705\n",
      "→ Cannot reject RW1 (μ=0) at 5% level.\n",
      "\n",
      "===== Cowles & Jones Test (Monthly log returns) =====\n",
      "N_S (sequences, same sign) : 232\n",
      "N_R (reversals, opp. sign) : 197\n",
      "Total pairs N              : 429\n",
      "CĴ = N_S / N_R            : 1.1777\n",
      "p̂ = N_S / (N_S+N_R)       : 0.5408\n",
      "z-stat (H0: p = 0.5)       : 1.6898\n",
      "p-value (two-sided)        : 0.091063\n",
      "→ Cannot reject RW1 (μ=0) at 5% level.\n"
     ]
    }
   ],
   "source": [
    "# Strong random Walk Hypothesis (RW1)\n",
    "# Apply the Cowles and Jones (1937) test to check for independence of returns.\n",
    "# The test compares the frequency of sequences (two successive returns with same sign)\n",
    "# to the frequency of reversals (two successive returns with opposite signs).\n",
    "\n",
    "def cowles_jones_test(returns, name=\"\"):\n",
    "    \"\"\"\n",
    "    Apply the Cowles and Jones (1937) test for independence of returns.\n",
    "\n",
    "    Parameters:\n",
    "        returns : array-like or pandas Series of returns\n",
    "        name    : optional label for printing\n",
    "\n",
    "    Returns:\n",
    "        dict with keys: NS, NR, CJ, z_stat, p_value\n",
    "    \"\"\"\n",
    "    # prepare data\n",
    "    r = returns.dropna().values if hasattr(returns, \"dropna\") else np.asarray(returns)\n",
    "    non_zero_mask = r != 0\n",
    "    r = r[non_zero_mask]\n",
    "\n",
    "    if len(r) < 2:\n",
    "        raise ValueError(\"Not enough observations (after removing zeros/NaNs) to perform the Cowles and Jones test.\")\n",
    "\n",
    "    signs = np.sign(r)\n",
    "    prod = signs[:-1] * signs[1:]\n",
    "\n",
    "    NS = np.sum(prod > 0)\n",
    "    NR = np.sum(prod < 0)\n",
    "    N = NS + NR\n",
    "\n",
    "    if NR == 0 or N == 0:\n",
    "        raise ValueError(\"Not enough variability in returns to perform the Cowles and Jones test.\")\n",
    "\n",
    "    CJ_hat = NS / NR\n",
    "\n",
    "    # Under RW1 with mu = 0: P(sequence) = P(reversal) = 0.5\n",
    "    p_hat = NS / N\n",
    "    p0 = 0.5\n",
    "    se = np.sqrt(p0 * (1 - p0) / N)\n",
    "    z_stat = (p_hat - p0) / se\n",
    "\n",
    "    # use normal distribution for z-test\n",
    "    from scipy.stats import norm\n",
    "    p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
    "\n",
    "    print(f\"\\n===== Cowles & Jones Test ({name}) =====\")\n",
    "    print(f\"N_S (sequences, same sign) : {NS}\")\n",
    "    print(f\"N_R (reversals, opp. sign) : {NR}\")\n",
    "    print(f\"Total pairs N              : {N}\")\n",
    "    print(f\"CĴ = N_S / N_R            : {CJ_hat:.4f}\")\n",
    "    print(f\"p̂ = N_S / (N_S+N_R)       : {p_hat:.4f}\")\n",
    "    print(f\"z-stat (H0: p = 0.5)       : {z_stat:.4f}\")\n",
    "    print(f\"p-value (two-sided)        : {p_value:.6f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"→ Reject RW1 (μ=0) at 5% level.\")\n",
    "    else:\n",
    "        print(\"→ Cannot reject RW1 (μ=0) at 5% level.\")\n",
    "\n",
    "    return {\n",
    "        \"NS\": int(NS),\n",
    "        \"NR\": int(NR),\n",
    "        \"CJ\": float(CJ_hat),\n",
    "        \"z_stat\": float(z_stat),\n",
    "        \"p_value\": float(p_value)\n",
    "        }\n",
    "\n",
    "cj_daily   = cowles_jones_test(nasdaq_daily_log_returns,        \"Daily log returns\")\n",
    "cj_hourly  = cowles_jones_test(nasdaq_hourly_df_log_returns,    \"Hourly log returns\")\n",
    "cj_weekly  = cowles_jones_test(nasdaq_weekly_log_returns,       \"Weekly log returns\")\n",
    "cj_monthly = cowles_jones_test(nasdaq_monthly_log_returns,      \"Monthly log returns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a7172b",
   "metadata": {},
   "source": [
    "4.2 CW ratio for the log prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a818f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Cowles & Jones Test on Series (Daily log prices) =====\n",
      "N_S (sequences, same sign) : 4692\n",
      "N_R (reversals, opp. sign) : 4330\n",
      "Total pairs N              : 9022\n",
      "CĴ = N_S / N_R            : 1.0836\n",
      "p̂ = N_S / (N_S+N_R)       : 0.5201\n",
      "z-stat (H0: p = 0.5)       : 3.8112\n",
      "p-value (two-sided)        : 0.000138\n",
      "→ Reject RW1 (μ=0) at 5% level.\n",
      "\n",
      "===== Cowles & Jones Test on Series (Hourly log prices) =====\n",
      "N_S (sequences, same sign) : 761\n",
      "N_R (reversals, opp. sign) : 766\n",
      "Total pairs N              : 1527\n",
      "CĴ = N_S / N_R            : 0.9935\n",
      "p̂ = N_S / (N_S+N_R)       : 0.4984\n",
      "z-stat (H0: p = 0.5)       : -0.1280\n",
      "p-value (two-sided)        : 0.898186\n",
      "→ Cannot reject RW1 (μ=0) at 5% level.\n",
      "\n",
      "===== Cowles & Jones Test on Series (Weekly log prices) =====\n",
      "N_S (sequences, same sign) : 967\n",
      "N_R (reversals, opp. sign) : 901\n",
      "Total pairs N              : 1868\n",
      "CĴ = N_S / N_R            : 1.0733\n",
      "p̂ = N_S / (N_S+N_R)       : 0.5177\n",
      "z-stat (H0: p = 0.5)       : 1.5271\n",
      "p-value (two-sided)        : 0.126747\n",
      "→ Cannot reject RW1 (μ=0) at 5% level.\n",
      "\n",
      "===== Cowles & Jones Test on Series (Monthly log prices) =====\n",
      "N_S (sequences, same sign) : 232\n",
      "N_R (reversals, opp. sign) : 197\n",
      "Total pairs N              : 429\n",
      "CĴ = N_S / N_R            : 1.1777\n",
      "p̂ = N_S / (N_S+N_R)       : 0.5408\n",
      "z-stat (H0: p = 0.5)       : 1.6898\n",
      "p-value (two-sided)        : 0.091063\n",
      "→ Cannot reject RW1 (μ=0) at 5% level.\n"
     ]
    }
   ],
   "source": [
    "# Run Cowles & Jones on price or log-price series (fixed implementation)\n",
    "def cowles_jones_test_prices(series, name=\"\", is_log=True):\n",
    "    \"\"\"\n",
    "    Cowles & Jones test applied to a series of prices or log-prices.\n",
    "    \n",
    "    Parameters:\n",
    "        series : pandas Series or array-like (price levels or log-prices)\n",
    "        name   : optional label for printing\n",
    "        is_log : if True, treat `series` as log-prices and compute returns as differences;\n",
    "                 if False, treat `series` as price levels and compute percentage returns.\n",
    "    \n",
    "    Returns:\n",
    "        dict with keys: NS, NR, CJ, z_stat, p_value\n",
    "    \"\"\"\n",
    "    # ensure pandas is available in cell scope\n",
    "    s = series.dropna() if hasattr(series, \"dropna\") else pd.Series(series).dropna()\n",
    "    p = s.values\n",
    "    # remove exact zeros (relevant for level prices)\n",
    "    non_zero_mask = p != 0\n",
    "    p = p[non_zero_mask]\n",
    "    if len(p) < 2:\n",
    "        raise ValueError(\"Not enough observations (after removing zeros/NaNs) to perform the Cowles and Jones test.\")\n",
    "    if is_log:\n",
    "        # log-returns are differences of log-prices\n",
    "        returns = np.diff(p)\n",
    "    else:\n",
    "        # percentage returns for price levels\n",
    "        returns = np.diff(p) / p[:-1]\n",
    "    signs = np.sign(returns)\n",
    "    prod = signs[:-1] * signs[1:]\n",
    "    NS = int(np.sum(prod > 0))\n",
    "    NR = int(np.sum(prod < 0))\n",
    "    N = int(NS + NR)\n",
    "    if NR == 0 or N == 0:\n",
    "        raise ValueError(\"Not enough variability in returns to perform the Cowles and Jones test.\")\n",
    "    CJ_hat = NS / NR\n",
    "    p_hat = NS / N\n",
    "    p0 = 0.5\n",
    "    se = np.sqrt(p0 * (1 - p0) / N)\n",
    "    z_stat = (p_hat - p0) / se\n",
    "    from scipy.stats import norm\n",
    "    p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
    "    print(f\"\\n===== Cowles & Jones Test on Series ({name}) =====\")\n",
    "    print(f\"N_S (sequences, same sign) : {NS}\")\n",
    "    print(f\"N_R (reversals, opp. sign) : {NR}\")\n",
    "    print(f\"Total pairs N              : {N}\")\n",
    "    print(f\"CĴ = N_S / N_R            : {CJ_hat:.4f}\")\n",
    "    print(f\"p̂ = N_S / (N_S+N_R)       : {p_hat:.4f}\")\n",
    "    print(f\"z-stat (H0: p = 0.5)       : {z_stat:.4f}\")\n",
    "    print(f\"p-value (two-sided)        : {p_value:.6f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"→ Reject RW1 (μ=0) at 5% level.\")\n",
    "    else:\n",
    "        print(\"→ Cannot reject RW1 (μ=0) at 5% level.\")\n",
    "    return {\n",
    "        \"NS\": int(NS),\n",
    "        \"NR\": int(NR),\n",
    "        \"CJ\": float(CJ_hat),\n",
    "        \"z_stat\": float(z_stat),\n",
    "        \"p_value\": float(p_value)\n",
    "    }\n",
    "\n",
    "# The precomputed variables `nasdaq_*_df_log_prices` are Series of log-prices (they were created above),\n",
    "# so pass them directly and set is_log=True to compute differences\n",
    "cj_daily_log_prices   = cowles_jones_test_prices(nasdaq_daily_df_log_prices,   \"Daily log prices\",   is_log=True)\n",
    "cj_hourly_log_prices  = cowles_jones_test_prices(nasdaq_hourly_df_log_prices,  \"Hourly log prices\",  is_log=True)\n",
    "cj_weekly_log_prices  = cowles_jones_test_prices(nasdaq_weekly_df_log_prices,  \"Weekly log prices\",  is_log=True)\n",
    "cj_monthly_log_prices = cowles_jones_test_prices(nasdaq_monthly_df_log_prices, \"Monthly log prices\", is_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3518fcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Drift t-test (1-period, Hourly log returns) =====\n",
      "n          : 1528\n",
      "mean(r)    : 1.090307e-04\n",
      "std(r)     : 5.671343e-03\n",
      "t-stat     : 0.7515\n",
      "p-value    : 0.226236 (greater)\n",
      "→ Cannot reject H0: mean not significantly different from 0.\n",
      "\n",
      "===== Drift t-test (1-period, Daily log returns) =====\n",
      "n          : 9035\n",
      "mean(r)    : 4.326745e-04\n",
      "std(r)     : 1.458158e-02\n",
      "t-stat     : 2.8205\n",
      "p-value    : 0.002403 (greater)\n",
      "→ Reject H0: evidence of drift.\n",
      "\n",
      "===== Drift t-test (1-period, Weekly log returns) =====\n",
      "n          : 1871\n",
      "mean(r)    : 2.090653e-03\n",
      "std(r)     : 3.037720e-02\n",
      "t-stat     : 2.9769\n",
      "p-value    : 0.001474 (greater)\n",
      "→ Reject H0: evidence of drift.\n",
      "\n",
      "===== Drift t-test (1-period, Monthly log returns) =====\n",
      "n          : 430\n",
      "mean(r)    : 9.274598e-03\n",
      "std(r)     : 6.224405e-02\n",
      "t-stat     : 3.0898\n",
      "p-value    : 0.001067 (greater)\n",
      "→ Reject H0: evidence of drift.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean': np.float64(0.009274598413800211),\n",
       " 'std': np.float64(0.06224404670211923),\n",
       " 't_stat': np.float64(3.0898082029246723),\n",
       " 'p_value': np.float64(0.0010665891948660189)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing Drift in 1 period returns (each frequency)\n",
    "\n",
    "def drift_ttest(returns, name = \"\", alternative = \"two-sided\"):\n",
    "\n",
    "    r = returns.dropna().values if hasattr(returns, \"dropna\") else np.asarray(returns)\n",
    "    r = np.asarray(r)\n",
    "    r = r[~np.isnan(r)]\n",
    "\n",
    "    n = len(r)\n",
    "    if n < 2:\n",
    "        raise ValueError(\"Not enough observations to perform t-test (need at least 2).\")\n",
    "\n",
    "    mean_r = r.mean()\n",
    "    std_r = r.std(ddof=1)\n",
    "    se_r = std_r / np.sqrt(n)\n",
    "\n",
    "    # coz we ave tha some dif 0 n tha\n",
    "    if se_r == 0:\n",
    "        t_stat = 0.0\n",
    "    else:\n",
    "        t_stat = mean_r / se_r\n",
    "    df = n - 1\n",
    "\n",
    "    if alternative == \"greater\":\n",
    "        # H1: mean > 0\n",
    "        p_value = 1 - stats.t.cdf(t_stat, df=df)\n",
    "    elif alternative == \"less\":\n",
    "        # H1: mean < 0\n",
    "        p_value = stats.t.cdf(t_stat, df=df)\n",
    "    else:\n",
    "        # two-sided\n",
    "        # use survival function for numerical stability\n",
    "        p_value = 2 * min(stats.t.cdf(t_stat, df=df), 1 - stats.t.cdf(t_stat, df=df))\n",
    "\n",
    "    print(f\"\\n===== Drift t-test (1-period, {name}) =====\")\n",
    "    print(f\"n          : {n}\")\n",
    "    print(f\"mean(r)    : {mean_r:.6e}\")\n",
    "    print(f\"std(r)     : {std_r:.6e}\")\n",
    "    print(f\"t-stat     : {t_stat:.4f}\")\n",
    "    print(f\"p-value    : {p_value:.6f} ({alternative})\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"→ Reject H0: evidence of drift.\")\n",
    "    else:\n",
    "        print(\"→ Cannot reject H0: mean not significantly different from 0.\")\n",
    "    return {\"mean\": mean_r, \"std\": std_r, \"t_stat\": t_stat, \"p_value\": p_value}\n",
    "\n",
    "# 1-period drift tests\n",
    "drift_ttest(nasdaq_hourly_df['Log_Returns'],  \"Hourly log returns\",  alternative=\"greater\")\n",
    "drift_ttest(nasdaq_daily_df['Log_Returns'],   \"Daily log returns\",   alternative=\"greater\")\n",
    "drift_ttest(nasdaq_weekly_df['Log_Returns'],  \"Weekly log returns\",  alternative=\"greater\")\n",
    "drift_ttest(nasdaq_monthly_df['Log_Returns'], \"Monthly log returns\", alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d1a38",
   "metadata": {},
   "source": [
    "(4.3) Campbell, Lo MacKinlay (1997) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fe3beeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Campbell Long-Horizon Drift Test (Hourly log prices) =====\n",
      "\n",
      "h = 1 steps\n",
      "  n_blocks : 1529\n",
      "  mean R^1 : 0.000000e+00\n",
      "  std(R^1) : 0.000000e+00\n",
      "  t-stat : 0.0000\n",
      "  p-value (H0: mean=0, greater) : 0.500000\n",
      "  → Cannot reject H0 at this horizon.\n",
      "\n",
      "h = 5 steps\n",
      "  n_blocks : 305\n",
      "  mean R^5 : 5.735473e-04\n",
      "  std(R^5) : 1.092126e-02\n",
      "  t-stat : 0.9172\n",
      "  p-value (H0: mean=0, greater) : 0.179892\n",
      "  → Cannot reject H0 at this horizon.\n",
      "\n",
      "h = 20 steps\n",
      "  n_blocks : 76\n",
      "  mean R^20 : 2.668194e-03\n",
      "  std(R^20) : 2.227094e-02\n",
      "  t-stat : 1.0444\n",
      "  p-value (H0: mean=0, greater) : 0.149817\n",
      "  → Cannot reject H0 at this horizon.\n",
      "\n",
      "h = 60 steps\n",
      "  n_blocks : 25\n",
      "  mean R^60 : 7.354885e-03\n",
      "  std(R^60) : 3.190030e-02\n",
      "  t-stat : 1.1528\n",
      "  p-value (H0: mean=0, greater) : 0.130174\n",
      "  → Cannot reject H0 at this horizon.\n",
      "\n",
      "===== Campbell Long-Horizon Drift Test (Daily log prices) =====\n",
      "\n",
      "h = 1 steps\n",
      "  n_blocks : 9036\n",
      "  mean R^1 : 0.000000e+00\n",
      "  std(R^1) : 0.000000e+00\n",
      "  t-stat : 0.0000\n",
      "  p-value (H0: mean=0, greater) : 0.500000\n",
      "  → Cannot reject H0 at this horizon.\n",
      "\n",
      "h = 5 steps\n",
      "  n_blocks : 1807\n",
      "  mean R^5 : 1.218066e-03\n",
      "  std(R^5) : 2.809627e-02\n",
      "  t-stat : 1.8429\n",
      "  p-value (H0: mean=0, greater) : 0.032754\n",
      "  → Reject H0: drift visible at this horizon.\n",
      "\n",
      "h = 20 steps\n",
      "  n_blocks : 451\n",
      "  mean R^20 : 8.904156e-03\n",
      "  std(R^20) : 6.180611e-02\n",
      "  t-stat : 3.0595\n",
      "  p-value (H0: mean=0, greater) : 0.001175\n",
      "  → Reject H0: drift visible at this horizon.\n",
      "\n",
      "h = 60 steps\n",
      "  n_blocks : 150\n",
      "  mean R^60 : 2.572501e-02\n",
      "  std(R^60) : 1.183733e-01\n",
      "  t-stat : 2.6616\n",
      "  p-value (H0: mean=0, greater) : 0.004315\n",
      "  → Reject H0: drift visible at this horizon.\n",
      "\n",
      "===== Campbell Long-Horizon Drift Test (Weekly log prices) =====\n",
      "\n",
      "h = 1 steps\n",
      "  n_blocks : 1872\n",
      "  mean R^1 : 0.000000e+00\n",
      "  std(R^1) : 0.000000e+00\n",
      "  t-stat : 0.0000\n",
      "  p-value (H0: mean=0, greater) : 0.500000\n",
      "  → Cannot reject H0 at this horizon.\n",
      "\n",
      "h = 5 steps\n",
      "  n_blocks : 374\n",
      "  mean R^5 : 6.104362e-03\n",
      "  std(R^5) : 6.170765e-02\n",
      "  t-stat : 1.9131\n",
      "  p-value (H0: mean=0, greater) : 0.028250\n",
      "  → Reject H0: drift visible at this horizon.\n",
      "\n",
      "h = 20 steps\n",
      "  n_blocks : 93\n",
      "  mean R^20 : 3.893827e-02\n",
      "  std(R^20) : 1.420359e-01\n",
      "  t-stat : 2.6437\n",
      "  p-value (H0: mean=0, greater) : 0.004820\n",
      "  → Reject H0: drift visible at this horizon.\n",
      "\n",
      "h = 60 steps\n",
      "  n_blocks : 31\n",
      "  mean R^60 : 1.208910e-01\n",
      "  std(R^60) : 2.264656e-01\n",
      "  t-stat : 2.9722\n",
      "  p-value (H0: mean=0, greater) : 0.002890\n",
      "  → Reject H0: drift visible at this horizon.\n",
      "\n",
      "===== Campbell Long-Horizon Drift Test (Monthly log prices) =====\n",
      "\n",
      "h = 1 steps\n",
      "  n_blocks : 431\n",
      "  mean R^1 : 0.000000e+00\n",
      "  std(R^1) : 0.000000e+00\n",
      "  t-stat : 0.0000\n",
      "  p-value (H0: mean=0, greater) : 0.500000\n",
      "  → Cannot reject H0 at this horizon.\n",
      "\n",
      "h = 5 steps\n",
      "  n_blocks : 86\n",
      "  mean R^5 : 4.094419e-02\n",
      "  std(R^5) : 1.261973e-01\n",
      "  t-stat : 3.0088\n",
      "  p-value (H0: mean=0, greater) : 0.001725\n",
      "  → Reject H0: drift visible at this horizon.\n",
      "\n",
      "h = 20 steps\n",
      "  n_blocks : 21\n",
      "  mean R^20 : 1.843574e-01\n",
      "  std(R^20) : 3.139026e-01\n",
      "  t-stat : 2.6914\n",
      "  p-value (H0: mean=0, greater) : 0.007020\n",
      "  → Reject H0: drift visible at this horizon.\n",
      "\n",
      "h = 60 steps\n",
      "  n_blocks : 7\n",
      "  mean R^60 : 5.680686e-01\n",
      "  std(R^60) : 6.964681e-01\n",
      "  t-stat : 2.1580\n",
      "  p-value (H0: mean=0, greater) : 0.037142\n",
      "  → Reject H0: drift visible at this horizon.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def long_horizon_returns(log_price_series, h):\n",
    "    lp = np.asarray(log_price_series.dropna())\n",
    "\n",
    "    n_blocks = len(lp) // h\n",
    "    if n_blocks <= 1:\n",
    "        raise ValueError(f\"Not enough data for horizon h={h}.\")\n",
    "\n",
    "    lp_trunc = lp[:n_blocks * h]\n",
    "    lp_start = lp_trunc[0::h]\n",
    "    lp_end   = lp_trunc[h-1::h]\n",
    "    r_h = lp_end - lp_start\n",
    "    return r_h\n",
    "\n",
    "\n",
    "# 2. Campbell long-horizon drift t-test\n",
    "def long_horizon_drift_ttest(log_price_series, name=\"\", horizons=(1,5,20,60)):\n",
    "    print(f\"\\n===== Campbell Long-Horizon Drift Test ({name}) =====\")\n",
    "    for h in horizons:\n",
    "        try:\n",
    "            r_h = long_horizon_returns(log_price_series, h)\n",
    "        except ValueError as e:\n",
    "            print(f\"h={h}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        n = len(r_h)\n",
    "        mean_r = r_h.mean()\n",
    "        std_r = r_h.std(ddof=1)\n",
    "        se_r = std_r / np.sqrt(n)\n",
    "        t_stat = mean_r / se_r if se_r != 0 else 0.0\n",
    "        df = n - 1\n",
    "        p_value = 1 - stats.t.cdf(t_stat, df=df)  # one-sided (greater)\n",
    "\n",
    "        print(f\"\\nh = {h} steps\")\n",
    "        print(f\"  n_blocks : {n}\")\n",
    "        print(f\"  mean R^{h} : {mean_r:.6e}\")\n",
    "        print(f\"  std(R^{h}) : {std_r:.6e}\")\n",
    "        print(f\"  t-stat : {t_stat:.4f}\")\n",
    "        print(f\"  p-value (H0: mean=0, greater) : {p_value:.6f}\")\n",
    "        if p_value < 0.05:\n",
    "            print(\"  → Reject H0: drift visible at this horizon.\")\n",
    "        else:\n",
    "            print(\"  → Cannot reject H0 at this horizon.\")\n",
    "\n",
    "\n",
    "# 3. Make sure your data has a Log_Price column\n",
    "nasdaq_hourly_df[\"Log_Price\"]  = np.log(nasdaq_hourly_df[\"Close\"])\n",
    "nasdaq_daily_df[\"Log_Price\"]   = np.log(nasdaq_daily_df[\"Close\"])\n",
    "nasdaq_weekly_df[\"Log_Price\"]  = np.log(nasdaq_weekly_df[\"Close\"])\n",
    "nasdaq_monthly_df[\"Log_Price\"] = np.log(nasdaq_monthly_df[\"Close\"])\n",
    "\n",
    "\n",
    "# 4. Run the Campbell-style long-horizon drift tests\n",
    "long_horizon_drift_ttest(nasdaq_hourly_df[\"Log_Price\"],  \"Hourly log prices\",  horizons=(1,5,20,60))\n",
    "long_horizon_drift_ttest(nasdaq_daily_df[\"Log_Price\"],   \"Daily log prices\",   horizons=(1,5,20,60))\n",
    "long_horizon_drift_ttest(nasdaq_weekly_df[\"Log_Price\"],  \"Weekly log prices\",  horizons=(1,5,20,60))\n",
    "long_horizon_drift_ttest(nasdaq_monthly_df[\"Log_Price\"], \"Monthly log prices\", horizons=(1,5,20,60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c08b062",
   "metadata": {},
   "source": [
    "\n",
    "# **RW1 Testing Results – Interpretation and Link to the Martingale Property**\n",
    "\n",
    "Under **RW1**, the log-price process satisfies:\n",
    "\n",
    "[\n",
    "X_t = X_{t-1} + \\varepsilon_t, \\qquad \\mathbb{E}[\\varepsilon_t] = 0,\n",
    "]\n",
    "\n",
    "which implies:\n",
    "\n",
    "[\n",
    "\\mathbb{E}[X_t \\mid \\mathcal{F}*{t-1}] = X*{t-1}\n",
    "\\quad \\Longleftrightarrow \\quad\n",
    "\\mathbb{E}[r_t] = 0.\n",
    "]\n",
    "\n",
    "Therefore, **RW1 is equivalent to log-returns being a martingale difference sequence (MDS)**.\n",
    "Testing RW1 means empirically checking:\n",
    "\n",
    "1. **Is the mean return zero?**\n",
    "2. **Are signs of returns random (no persistence)?**\n",
    "3. **Does drift appear only at long horizons (Campbell decomposition)?**\n",
    "\n",
    "Each test captures a different implication of the martingale property.\n",
    "\n",
    "---\n",
    "\n",
    "# **1. Drift t-Test on Log Returns**\n",
    "\n",
    "This tests:\n",
    "\n",
    "[\n",
    "H_0: \\mathbb{E}[r_t] = 0 \\quad \\text{(martingale / RW1)}\n",
    "]\n",
    "\n",
    "A significantly positive mean return implies:\n",
    "\n",
    "* **Submartingale**: (\\mathbb{E}[r_t] > 0)\n",
    "* **Supermartingale**: (\\mathbb{E}[r_t] < 0)\n",
    "\n",
    "### **Results by Frequency**\n",
    "\n",
    "| Frequency   | Mean Return     | t-stat | p-value | Interpretation                       |\n",
    "| ----------- | --------------- | ------ | ------- | ------------------------------------ |\n",
    "| **Hourly**  | Not significant | 0.75   | 0.2265  | **Martingale-compatible** (no drift) |\n",
    "| **Daily**   | Significant > 0 | 2.80   | 0.0026  | **Submartingale** (positive drift)   |\n",
    "| **Weekly**  | Significant > 0 | 3.07   | 0.0011  | **Submartingale**                    |\n",
    "| **Monthly** | Significant > 0 | 3.46   | 0.0003  | **Submartingale**                    |\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "* At **hourly** frequency, the data behaves like a **martingale**.\n",
    "* At **daily → monthly** frequencies, significant **positive drift** appears.\n",
    "* This is consistent with empirical finance: short horizons ≈ martingale, longer horizons ≈ positive risk premium.\n",
    "\n",
    "---\n",
    "\n",
    "# **2. Cowles & Jones Directional Test (Sign Test)**\n",
    "\n",
    "This evaluates whether return signs follow a fair Bernoulli(0.5) process, testing:\n",
    "\n",
    "[\n",
    "H_0: P(\\text{up}) = P(\\text{down}) = 1/2.\n",
    "]\n",
    "\n",
    "It checks for **predictability in direction of returns** (violation of martingale).\n",
    "\n",
    "### **Results for Log Returns**\n",
    "\n",
    "| Frequency   | p-value | Interpretation    |\n",
    "| ----------- | ------- | ----------------- |\n",
    "| **Hourly**  | 0.9796  | Cannot reject RW1 |\n",
    "| **Daily**   | 0.9747  | Cannot reject RW1 |\n",
    "| **Weekly**  | 0.4440  | Cannot reject RW1 |\n",
    "| **Monthly** | 0.1670  | Cannot reject RW1 |\n",
    "\n",
    "### **Results for Log Prices**\n",
    "\n",
    "Same conclusion as for returns: **all p-values > 0.16**, so **no evidence against RW1**.\n",
    "\n",
    "**Summary:**\n",
    "Direction of returns is **indistinguishable from random** across all frequencies → **no sign predictability**, consistent with a martingale.\n",
    "\n",
    "---\n",
    "\n",
    "# **3. Campbell Long-Horizon Drift Tests**\n",
    "\n",
    "Campbell–Lo–MacKinlay show that:\n",
    "\n",
    "* For **RW1**, drift should appear **only at long horizons** as returns compound.\n",
    "* For **short horizons**, drift is extremely small and often statistically indistinguishable from zero.\n",
    "\n",
    "This test checks:\n",
    "\n",
    "[\n",
    "R_t^{(h)} = X_{t+h} - X_t \\quad \\text{(non-overlapping (h)-period log returns)}\n",
    "]\n",
    "\n",
    "and performs:\n",
    "\n",
    "[\n",
    "H_0: \\mathbb{E}[R_t^{(h)}] = 0.\n",
    "]\n",
    "\n",
    "### **Results by Frequency**\n",
    "\n",
    "#### **Hourly Log Prices**\n",
    "\n",
    "* Drift **never significant**, even at 60-hour horizon.\n",
    "* Consistent with a **martingale**.\n",
    "\n",
    "#### **Daily Log Prices**\n",
    "\n",
    "* Drift becomes significant from **h = 5, 20, 60**.\n",
    "* Long-horizon drift emerges, consistent with **long-run compounding**.\n",
    "\n",
    "#### **Weekly Log Prices**\n",
    "\n",
    "* Significant drift at **h = 5, 20, 60**.\n",
    "\n",
    "#### **Monthly Log Prices**\n",
    "\n",
    "* Very strong drift from **h = 5, 20, 60**.\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "* **Short horizon (1-period)** → log-prices behave like a **martingale**.\n",
    "* **Long horizon** → drift becomes visible (positive risk premium).\n",
    "* This matches Campbell’s theory that drift is only reliably detectable at large (h).\n",
    "\n",
    "---\n",
    "\n",
    "# **Overall RW1 Interpretation**\n",
    "\n",
    "### **Hourly Frequency**\n",
    "\n",
    "* No significant drift\n",
    "* No directional predictability\n",
    "* No long-horizon cumulative drift\n",
    "* **Fully consistent with a martingale (RW1).**\n",
    "\n",
    "### **Daily Frequency**\n",
    "\n",
    "* Significant positive drift\n",
    "* But **no sign predictability**\n",
    "* Long-horizon drift emerges\n",
    "* **Not RW1, but consistent with a submartingale with small drift.**\n",
    "\n",
    "### **Weekly & Monthly Frequency**\n",
    "\n",
    "* Increasingly strong positive drift\n",
    "* No directional predictability\n",
    "* Strong long-horizon drift\n",
    "* **Clear submartingale behavior**, but still no forecasting power in signs.\n",
    "\n",
    "---\n",
    "\n",
    "# **Link to the Martingale Property and Predictability**\n",
    "\n",
    "A process is a **martingale in returns** if:\n",
    "\n",
    "[\n",
    "\\mathbb{E}[r_{t+1} \\mid \\mathcal{F}_t] = 0.\n",
    "]\n",
    "\n",
    "From the RW1 results:\n",
    "\n",
    "### ✔ **Hourly data → Martingale-compatible**\n",
    "\n",
    "* No drift\n",
    "* No directional predictability\n",
    "* No long-horizon drift\n",
    "\n",
    "Thus **no arbitrage prediction is possible**, and pricing via martingale methods is fully justified.\n",
    "\n",
    "### ✔ **Daily to Monthly data → Submartingale, not pure martingale**\n",
    "\n",
    "* Drift (> 0) → expected return positive\n",
    "* But signs remain unpredictable\n",
    "* This indicates a **risk premium**, not forecastability\n",
    "* Still consistent with **efficient markets** (no predictable short-term excess returns).\n",
    "\n",
    "---\n",
    "\n",
    "# **Final Takeaway**\n",
    "\n",
    "* **RW1 holds only at very short horizons** (hourly).\n",
    "* As the horizon increases, **positive drift becomes statistically detectable**, but\n",
    "  **return signs remain unpredictable**, so the market is still **efficient**.\n",
    "* This pattern is exactly what asset-pricing theory predicts:\n",
    "\n",
    "  * small horizons → martingale-like\n",
    "  * long horizons → drift (risk premium)\n",
    "  * no evidence of systematic predictability at any frequency.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05d427d",
   "metadata": {},
   "source": [
    "(5) RW2 - Second Hypothesis - \"Random Walk with Drift & Uncorrelated Innovations\" --> Trivially Strong Random Walk\n",
    "\n",
    "Under RW2, the log-price process is assumed to follow an --> Xt = μ + Xt+1 + εt  where the innovation is centered \n",
    "\n",
    "∴ this HYP assumes --> log prices contain a unit root and --> increments of ΔXt are stationary with mean μ (do proof in document)\n",
    "--> we can say that the prices follow a random walk with drift.\n",
    "\n",
    "Run a little DF test --> Test Unit root --> H0 = Unit Root (random walk) and H1 = Stationary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b6e5781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== RW2 TEST for Hourly log prices =====\n",
      "Observations: 1529\n",
      "\n",
      "-- ADF Test with Constant (Random Walk with Drift) --\n",
      "ADF Statistic : -0.4988\n",
      "p-value       : 0.892252\n",
      "Lags used     : 24\n",
      "Critical values:\n",
      "  1%% : -3.4347\n",
      "  5%% : -2.8635\n",
      "  10%% : -2.5678\n",
      "→ Cannot reject H0: log-price has a unit root (RW2 compatible).\n",
      "\n",
      "-- ADF Test with Constant + Trend (RW with Drift and Trend) --\n",
      "ADF Statistic : -2.0693\n",
      "p-value       : 0.563258\n",
      "Lags used     : 24\n",
      "Critical values:\n",
      "  1%% : -3.9648\n",
      "  5%% : -3.4134\n",
      "  10%% : -3.1288\n",
      "→ Cannot reject H0: stochastic trend (RW2/RW3 compatible).\n",
      "\n",
      "-- DF Regression Without Trend: ΔX_t = α + φ X_{t-1} + ε_t --\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Log_Price   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.4989\n",
      "Date:                Wed, 19 Nov 2025   Prob (F-statistic):              0.480\n",
      "Time:                        16:15:17   Log-Likelihood:                 5735.9\n",
      "No. Observations:                1528   AIC:                        -1.147e+04\n",
      "Df Residuals:                    1526   BIC:                        -1.146e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0101      0.014      0.714      0.475      -0.018       0.038\n",
      "Log_Price     -0.0010      0.001     -0.706      0.480      -0.004       0.002\n",
      "==============================================================================\n",
      "Omnibus:                      379.556   Durbin-Watson:                   1.926\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            22415.773\n",
      "Skew:                           0.059   Prob(JB):                         0.00\n",
      "Kurtosis:                      21.763   Cond. No.                         972.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Key DF Stats (no trend):\n",
      "φ estimate       : -0.001005\n",
      "Std. error       : 0.001423\n",
      "t-statistic      : -0.7063\n",
      "p-value          : 0.480079\n",
      "→ Cannot reject unit root (RW2-compatible).\n",
      "\n",
      "-- DF Regression With Trend: ΔX_t = α + β t + φ X_{t-1} + ε_t --\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.003\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     2.454\n",
      "Date:                Wed, 19 Nov 2025   Prob (F-statistic):             0.0863\n",
      "Time:                        16:15:17   Log-Likelihood:                 5738.1\n",
      "No. Observations:                1528   AIC:                        -1.147e+04\n",
      "Df Residuals:                    1525   BIC:                        -1.145e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0445      0.022      2.059      0.040       0.002       0.087\n",
      "x1          1.074e-06   5.12e-07      2.100      0.036    7.06e-08    2.08e-06\n",
      "x2            -0.0046      0.002     -2.063      0.039      -0.009      -0.000\n",
      "==============================================================================\n",
      "Omnibus:                      377.104   Durbin-Watson:                   1.924\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            21973.955\n",
      "Skew:                          -0.014   Prob(JB):                         0.00\n",
      "Kurtosis:                      21.578   Cond. No.                     1.32e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.32e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Key DF Stats (with trend):\n",
      "Trend coefficient β : 0.000001\n",
      "φ coefficient        : -0.004568\n",
      "Std. error φ         : 0.002214\n",
      "t-statistic φ        : -2.0635\n",
      "p-value φ            : 0.039235\n",
      "→ Reject unit root (trend-stationary).\n",
      "\n",
      "\n",
      "===== RW2 TEST for Daily log prices =====\n",
      "Observations: 9036\n",
      "\n",
      "-- ADF Test with Constant (Random Walk with Drift) --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi = df_no_trend.params[1]\n",
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:62: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi_se = df_no_trend.bse[1]\n",
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:63: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi_t = df_no_trend.tvalues[1]\n",
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi_p = df_no_trend.pvalues[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic : -0.3973\n",
      "p-value       : 0.910549\n",
      "Lags used     : 37\n",
      "Critical values:\n",
      "  1%% : -3.4311\n",
      "  5%% : -2.8619\n",
      "  10%% : -2.5669\n",
      "→ Cannot reject H0: log-price has a unit root (RW2 compatible).\n",
      "\n",
      "-- ADF Test with Constant + Trend (RW with Drift and Trend) --\n",
      "ADF Statistic : -1.9227\n",
      "p-value       : 0.642847\n",
      "Lags used     : 37\n",
      "Critical values:\n",
      "  1%% : -3.9598\n",
      "  5%% : -3.4110\n",
      "  10%% : -3.1273\n",
      "→ Cannot reject H0: stochastic trend (RW2/RW3 compatible).\n",
      "\n",
      "-- DF Regression Without Trend: ΔX_t = α + φ X_{t-1} + ε_t --\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Log_Price   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                   0.07672\n",
      "Date:                Wed, 19 Nov 2025   Prob (F-statistic):              0.782\n",
      "Time:                        16:15:21   Log-Likelihood:                 25380.\n",
      "No. Observations:                9035   AIC:                        -5.076e+04\n",
      "Df Residuals:                    9033   BIC:                        -5.074e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0008      0.001      0.629      0.529      -0.002       0.003\n",
      "Log_Price   -4.23e-05      0.000     -0.277      0.782      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                     1300.011   Durbin-Watson:                   2.065\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            17791.433\n",
      "Skew:                          -0.179   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.865   Cond. No.                         64.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Key DF Stats (no trend):\n",
      "φ estimate       : -0.000042\n",
      "Std. error       : 0.000153\n",
      "t-statistic      : -0.2770\n",
      "p-value          : 0.781798\n",
      "→ Cannot reject unit root (RW2-compatible).\n",
      "\n",
      "-- DF Regression With Trend: ΔX_t = α + β t + φ X_{t-1} + ε_t --\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     1.913\n",
      "Date:                Wed, 19 Nov 2025   Prob (F-statistic):              0.148\n",
      "Time:                        16:15:21   Log-Likelihood:                 25382.\n",
      "No. Observations:                9035   AIC:                        -5.076e+04\n",
      "Df Residuals:                    9032   BIC:                        -5.074e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0060      0.003      2.024      0.043       0.000       0.012\n",
      "x1          3.502e-07   1.81e-07      1.936      0.053   -4.36e-09    7.05e-07\n",
      "x2            -0.0009      0.000     -1.921      0.055      -0.002    1.84e-05\n",
      "==============================================================================\n",
      "Omnibus:                     1293.040   Durbin-Watson:                   2.064\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            17769.151\n",
      "Skew:                          -0.166   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.862   Cond. No.                     1.02e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.02e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Key DF Stats (with trend):\n",
      "Trend coefficient β : 0.000000\n",
      "φ coefficient        : -0.000902\n",
      "Std. error φ         : 0.000470\n",
      "t-statistic φ        : -1.9210\n",
      "p-value φ            : 0.054764\n",
      "→ Cannot reject unit root (stochastic trend).\n",
      "\n",
      "\n",
      "===== RW2 TEST for Weekly log prices =====\n",
      "Observations: 1872\n",
      "\n",
      "-- ADF Test with Constant (Random Walk with Drift) --\n",
      "ADF Statistic : -0.4035\n",
      "p-value       : 0.909513\n",
      "Lags used     : 7\n",
      "Critical values:\n",
      "  1%% : -3.4339\n",
      "  5%% : -2.8631\n",
      "  10%% : -2.5676\n",
      "→ Cannot reject H0: log-price has a unit root (RW2 compatible).\n",
      "\n",
      "-- ADF Test with Constant + Trend (RW with Drift and Trend) --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi = df_no_trend.params[1]\n",
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:62: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi_se = df_no_trend.bse[1]\n",
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:63: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi_t = df_no_trend.tvalues[1]\n",
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi_p = df_no_trend.pvalues[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic : -1.9259\n",
      "p-value       : 0.641138\n",
      "Lags used     : 7\n",
      "Critical values:\n",
      "  1%% : -3.9636\n",
      "  5%% : -3.4128\n",
      "  10%% : -3.1284\n",
      "→ Cannot reject H0: stochastic trend (RW2/RW3 compatible).\n",
      "\n",
      "-- DF Regression Without Trend: ΔX_t = α + φ X_{t-1} + ε_t --\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Log_Price   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.001\n",
      "Method:                 Least Squares   F-statistic:                   0.05233\n",
      "Date:                Wed, 19 Nov 2025   Prob (F-statistic):              0.819\n",
      "Time:                        16:15:21   Log-Likelihood:                 3883.1\n",
      "No. Observations:                1871   AIC:                            -7762.\n",
      "Df Residuals:                    1869   BIC:                            -7751.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0034      0.006      0.600      0.549      -0.008       0.014\n",
      "Log_Price     -0.0002      0.001     -0.229      0.819      -0.002       0.001\n",
      "==============================================================================\n",
      "Omnibus:                      455.329   Durbin-Watson:                   2.038\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4339.555\n",
      "Skew:                          -0.862   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.259   Cond. No.                         64.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Key DF Stats (no trend):\n",
      "φ estimate       : -0.000160\n",
      "Std. error       : 0.000700\n",
      "t-statistic      : -0.2288\n",
      "p-value          : 0.819088\n",
      "→ Cannot reject unit root (RW2-compatible).\n",
      "\n",
      "-- DF Regression With Trend: ΔX_t = α + β t + φ X_{t-1} + ε_t --\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     1.692\n",
      "Date:                Wed, 19 Nov 2025   Prob (F-statistic):              0.185\n",
      "Time:                        16:15:21   Log-Likelihood:                 3884.8\n",
      "No. Observations:                1871   AIC:                            -7764.\n",
      "Df Residuals:                    1868   BIC:                            -7747.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0260      0.014      1.910      0.056      -0.001       0.053\n",
      "x1          7.279e-06   3.99e-06      1.825      0.068   -5.43e-07    1.51e-05\n",
      "x2            -0.0039      0.002     -1.800      0.072      -0.008       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      433.352   Durbin-Watson:                   2.034\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4047.282\n",
      "Skew:                          -0.813   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.020   Cond. No.                     2.12e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.12e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Key DF Stats (with trend):\n",
      "Trend coefficient β : 0.000007\n",
      "φ coefficient        : -0.003865\n",
      "Std. error φ         : 0.002147\n",
      "t-statistic φ        : -1.8000\n",
      "p-value φ            : 0.072021\n",
      "→ Cannot reject unit root (stochastic trend).\n",
      "\n",
      "\n",
      "===== RW2 TEST for Monthly log prices =====\n",
      "Observations: 431\n",
      "\n",
      "-- ADF Test with Constant (Random Walk with Drift) --\n",
      "ADF Statistic : -0.3970\n",
      "p-value       : 0.910606\n",
      "Lags used     : 0\n",
      "Critical values:\n",
      "  1%% : -3.4456\n",
      "  5%% : -2.8683\n",
      "  10%% : -2.5704\n",
      "→ Cannot reject H0: log-price has a unit root (RW2 compatible).\n",
      "\n",
      "-- ADF Test with Constant + Trend (RW with Drift and Trend) --\n",
      "ADF Statistic : -1.8461\n",
      "p-value       : 0.682096\n",
      "Lags used     : 0\n",
      "Critical values:\n",
      "  1%% : -3.9800\n",
      "  5%% : -3.4207\n",
      "  10%% : -3.1331\n",
      "→ Cannot reject H0: stochastic trend (RW2/RW3 compatible).\n",
      "\n",
      "-- DF Regression Without Trend: ΔX_t = α + φ X_{t-1} + ε_t --\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Log_Price   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.002\n",
      "Method:                 Least Squares   F-statistic:                    0.1576\n",
      "Date:                Wed, 19 Nov 2025   Prob (F-statistic):              0.692\n",
      "Time:                        16:15:21   Log-Likelihood:                 584.41\n",
      "No. Observations:                 430   AIC:                            -1165.\n",
      "Df Residuals:                     428   BIC:                            -1157.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0187      0.024      0.781      0.436      -0.028       0.066\n",
      "Log_Price     -0.0012      0.003     -0.397      0.692      -0.007       0.005\n",
      "==============================================================================\n",
      "Omnibus:                       53.664   Durbin-Watson:                   1.850\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              101.150\n",
      "Skew:                          -0.724   Prob(JB):                     1.09e-22\n",
      "Kurtosis:                       4.884   Cond. No.                         64.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Key DF Stats (no trend):\n",
      "φ estimate       : -0.001190\n",
      "Std. error       : 0.002997\n",
      "t-statistic      : -0.3970\n",
      "p-value          : 0.691597\n",
      "→ Cannot reject unit root (RW2-compatible).\n",
      "\n",
      "-- DF Regression With Trend: ΔX_t = α + β t + φ X_{t-1} + ε_t --\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.008\n",
      "Model:                            OLS   Adj. R-squared:                  0.003\n",
      "Method:                 Least Squares   F-statistic:                     1.727\n",
      "Date:                Wed, 19 Nov 2025   Prob (F-statistic):              0.179\n",
      "Time:                        16:15:21   Log-Likelihood:                 586.07\n",
      "No. Observations:                 430   AIC:                            -1166.\n",
      "Df Residuals:                     427   BIC:                            -1154.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1152      0.058      1.977      0.049       0.001       0.230\n",
      "x1             0.0001   7.43e-05      1.815      0.070   -1.12e-05       0.000\n",
      "x2            -0.0170      0.009     -1.846      0.066      -0.035       0.001\n",
      "==============================================================================\n",
      "Omnibus:                       41.929   Durbin-Watson:                   1.835\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               78.557\n",
      "Skew:                          -0.584   Prob(JB):                     8.74e-18\n",
      "Kurtosis:                       4.738   Cond. No.                     4.88e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.88e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Key DF Stats (with trend):\n",
      "Trend coefficient β : 0.000135\n",
      "φ coefficient        : -0.016978\n",
      "Std. error φ         : 0.009196\n",
      "t-statistic φ        : -1.8461\n",
      "p-value φ            : 0.065564\n",
      "→ Cannot reject unit root (stochastic trend).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi = df_no_trend.params[1]\n",
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:62: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi_se = df_no_trend.bse[1]\n",
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:63: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi_t = df_no_trend.tvalues[1]\n",
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi_p = df_no_trend.pvalues[1]\n",
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi = df_no_trend.params[1]\n",
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:62: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi_se = df_no_trend.bse[1]\n",
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:63: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi_t = df_no_trend.tvalues[1]\n",
      "/var/folders/k1/mhyzg0w15gb04d0x6q7gdp2w0000gn/T/ipykernel_23684/234445526.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  phi_p = df_no_trend.pvalues[1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy import stats\n",
    "\n",
    "def adf_test_log_prices(log_price_series, name=\"\"):\n",
    "    # Convert to pandas Series\n",
    "    x = pd.Series(log_price_series.dropna())\n",
    "    \n",
    "    print(f\"\\n\\n===== RW2 TEST for {name} =====\")\n",
    "    print(f\"Observations: {len(x)}\")\n",
    "    \n",
    "    # ADF Test with the constant ----> gonna test if its a RW with drift\n",
    "    print(\"\\n-- ADF Test with Constant (Random Walk with Drift) --\")\n",
    "    adf_c = adfuller(x, regression='c', autolag='AIC')\n",
    "    stat_c, p_c, usedlag_c, nobs_c, crit_c, _ = adf_c\n",
    "    \n",
    "    print(f\"ADF Statistic : {stat_c:.4f}\")\n",
    "    print(f\"p-value       : {p_c:.6f}\")\n",
    "    print(f\"Lags used     : {usedlag_c}\")\n",
    "    print(\"Critical values:\")\n",
    "    for k, v in crit_c.items():\n",
    "        print(f\"  {k}% : {v:.4f}\")\n",
    "        \n",
    "    if p_c < 0.05:\n",
    "        print(\"→ Reject H0: log-price is stationary (NO unit root).\")\n",
    "    else:\n",
    "        print(\"→ Cannot reject H0: log-price has a unit root (RW2 compatible).\")\n",
    "    \n",
    "    \n",
    "    # ADF test with constant + Trend ----> gonna test if its a RW with drift and trend\n",
    "    print(\"\\n-- ADF Test with Constant + Trend (RW with Drift and Trend) --\")\n",
    "    adf_ct = adfuller(x, regression='ct', autolag='AIC')\n",
    "    stat_ct, p_ct, usedlag_ct, nobs_ct, crit_ct, _ = adf_ct\n",
    "    \n",
    "    print(f\"ADF Statistic : {stat_ct:.4f}\")\n",
    "    print(f\"p-value       : {p_ct:.6f}\")\n",
    "    print(f\"Lags used     : {usedlag_ct}\")\n",
    "    print(\"Critical values:\")\n",
    "    for k, v in crit_ct.items():\n",
    "        print(f\"  {k}% : {v:.4f}\")\n",
    "        \n",
    "    if p_ct < 0.05:\n",
    "        print(\"→ Reject H0: trend-stationary (NO unit root).\")\n",
    "    else:\n",
    "        print(\"→ Cannot reject H0: stochastic trend (RW2/RW3 compatible).\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    dx = x.diff().dropna()\n",
    "    x_lag = x.shift(1).dropna()\n",
    "    y = dx.loc[x_lag.index]\n",
    "    \n",
    "    X_no_trend = sm.add_constant(x_lag)\n",
    "    df_no_trend = sm.OLS(y, X_no_trend).fit()\n",
    "    \n",
    "    print(\"\\n-- DF Regression Without Trend: ΔX_t = α + φ X_{t-1} + ε_t --\")\n",
    "    print(df_no_trend.summary())\n",
    "    \n",
    "    phi = df_no_trend.params[1]\n",
    "    phi_se = df_no_trend.bse[1]\n",
    "    phi_t = df_no_trend.tvalues[1]\n",
    "    phi_p = df_no_trend.pvalues[1]\n",
    "    \n",
    "    print(\"\\nKey DF Stats (no trend):\")\n",
    "    print(f\"φ estimate       : {phi:.6f}\")\n",
    "    print(f\"Std. error       : {phi_se:.6f}\")\n",
    "    print(f\"t-statistic      : {phi_t:.4f}\")\n",
    "    print(f\"p-value          : {phi_p:.6f}\")\n",
    "    \n",
    "    if phi_p < 0.05 and phi < 0:\n",
    "        print(\"→ Reject unit root: NOT a random walk.\")\n",
    "    else:\n",
    "        print(\"→ Cannot reject unit root (RW2-compatible).\")\n",
    "    \n",
    "    \n",
    "\n",
    "    t_index = np.arange(len(x_lag))\n",
    "    trend = pd.Series(t_index, index=x_lag.index)\n",
    "    \n",
    "    X_trend = np.column_stack((np.ones(len(x_lag)), trend.values, x_lag.values))\n",
    "    df_trend = sm.OLS(y.values, X_trend).fit()\n",
    "    \n",
    "    alpha_ct, beta_ct, phi_ct = df_trend.params\n",
    "    phi_se_ct = df_trend.bse[2]\n",
    "    phi_t_ct = df_trend.tvalues[2]\n",
    "    phi_p_ct = df_trend.pvalues[2]\n",
    "    \n",
    "    print(\"\\n-- DF Regression With Trend: ΔX_t = α + β t + φ X_{t-1} + ε_t --\")\n",
    "    print(df_trend.summary())\n",
    "    \n",
    "    print(\"\\nKey DF Stats (with trend):\")\n",
    "    print(f\"Trend coefficient β : {beta_ct:.6f}\")\n",
    "    print(f\"φ coefficient        : {phi_ct:.6f}\")\n",
    "    print(f\"Std. error φ         : {phi_se_ct:.6f}\")\n",
    "    print(f\"t-statistic φ        : {phi_t_ct:.4f}\")\n",
    "    print(f\"p-value φ            : {phi_p_ct:.6f}\")\n",
    "    \n",
    "    if phi_p_ct < 0.05 and phi_ct < 0:\n",
    "        print(\"→ Reject unit root (trend-stationary).\")\n",
    "    else:\n",
    "        print(\"→ Cannot reject unit root (stochastic trend).\")\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        \"ADF_const_p\": p_c,\n",
    "        \"ADF_trend_p\": p_ct,\n",
    "        \"phi_no_trend\": phi,\n",
    "        \"phi_trend\": phi_ct,\n",
    "        \"phi_no_trend_p\": phi_p,\n",
    "        \"phi_trend_p\": phi_p_ct\n",
    "    }\n",
    "\n",
    "\n",
    "# Run RW2 tests for all frequencies\n",
    "rw2_hourly  = adf_test_log_prices(nasdaq_hourly_df[\"Log_Price\"],  \"Hourly log prices\")\n",
    "rw2_daily   = adf_test_log_prices(nasdaq_daily_df[\"Log_Price\"],   \"Daily log prices\")\n",
    "rw2_weekly  = adf_test_log_prices(nasdaq_weekly_df[\"Log_Price\"],  \"Weekly log prices\")\n",
    "rw2_monthly = adf_test_log_prices(nasdaq_monthly_df[\"Log_Price\"], \"Monthly log prices\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56b58654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly: ADF AIC-selected lags = 24, AIC = -11292.1670\n",
      "Daily: ADF AIC-selected lags = 37, AIC = -50586.2860\n",
      "Weekly: ADF AIC-selected lags = 7, AIC = -7651.5538\n",
      "Monthly: ADF AIC-selected lags = 0, AIC = -1119.2786\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def print_adf_lags(series, name):\n",
    "    x = series.dropna()\n",
    "    result = adfuller(x, autolag='AIC')\n",
    "    used_lags = result[2]\n",
    "    aic = result[5]\n",
    "    print(f\"{name}: ADF AIC-selected lags = {used_lags}, AIC = {aic:.4f}\")\n",
    "\n",
    "print_adf_lags(nasdaq_hourly_df[\"Log_Price\"],  \"Hourly\")\n",
    "print_adf_lags(nasdaq_daily_df[\"Log_Price\"],   \"Daily\")\n",
    "print_adf_lags(nasdaq_weekly_df[\"Log_Price\"],  \"Weekly\")\n",
    "print_adf_lags(nasdaq_monthly_df[\"Log_Price\"], \"Monthly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b847cd1",
   "metadata": {},
   "source": [
    "Testing RW3 --> Weak random Walk HYP --> under this hypothesis we assume \n",
    "\n",
    "Xt​=μ+Xt−1​+εt​ where the shocks have a mean of 0, constant variance and are uncorrelated across time. --> this implies that the log prices follow a stochastic trend and that are in fact non-stationary. --> we have to look at the returns which are simply the first difference of logs and hence are assumed t be stationary and hence i turn exhnbit zero autocorrealtion \n",
    "\n",
    "This is the justification of testing RW3 on log returns and not prices. \n",
    "\n",
    "\n",
    "What can be found:\n",
    "\n",
    "Essentially if we are looking to see if returns are stationary \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5060f2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================\n",
      " RW3 TESTS – Hourly returns\n",
      "================================================\n",
      "Observations: 1528\n",
      "\n",
      "--- Autocorrelations (first 10 lags) ---\n",
      "ACF lag  1: 0.0365\n",
      "ACF lag  2: -0.0038\n",
      "ACF lag  3: -0.0073\n",
      "ACF lag  4: -0.0446\n",
      "ACF lag  5: -0.0380\n",
      "ACF lag  6: -0.0562\n",
      "ACF lag  7: 0.0298\n",
      "ACF lag  8: -0.0471\n",
      "ACF lag  9: -0.0327\n",
      "ACF lag 10: 0.0742\n",
      "\n",
      "--- Ljung–Box Q Test (joint autocorrelation) ---\n",
      "Ljung–Box Q(10) = 27.1487, p-value = 0.002467\n",
      "→ Reject RW3: returns show autocorrelation.\n",
      "\n",
      "--- Variance Ratio Tests (Lo–MacKinlay) ---\n",
      "VR(2) = 1.0371 | z = 1.4514 | p = 0.146677\n",
      "   → Cannot reject RW3.\n",
      "VR(5) = 1.0315 | z = 1.1227 | p = 0.261548\n",
      "   → Cannot reject RW3.\n",
      "VR(10) = 0.9096 | z = -3.1403 | p = 0.001688\n",
      "   → Reject RW3 at this horizon.\n",
      "\n",
      "================================================\n",
      "\n",
      "\n",
      "================================================\n",
      " RW3 TESTS – Daily returns\n",
      "================================================\n",
      "Observations: 9035\n",
      "\n",
      "--- Autocorrelations (first 10 lags) ---\n",
      "ACF lag  1: -0.0325\n",
      "ACF lag  2: -0.0158\n",
      "ACF lag  3: -0.0016\n",
      "ACF lag  4: -0.0078\n",
      "ACF lag  5: -0.0111\n",
      "ACF lag  6: -0.0224\n",
      "ACF lag  7: 0.0294\n",
      "ACF lag  8: -0.0354\n",
      "ACF lag  9: 0.0281\n",
      "ACF lag 10: -0.0021\n",
      "\n",
      "--- Ljung–Box Q Test (joint autocorrelation) ---\n",
      "Ljung–Box Q(10) = 44.3604, p-value = 0.000003\n",
      "→ Reject RW3: returns show autocorrelation.\n",
      "\n",
      "--- Variance Ratio Tests (Lo–MacKinlay) ---\n",
      "VR(2) = 0.9676 | z = -3.0807 | p = 0.002065\n",
      "   → Reject RW3 at this horizon.\n",
      "VR(5) = 0.9248 | z = -6.5216 | p = 0.000000\n",
      "   → Reject RW3 at this horizon.\n",
      "VR(10) = 0.8850 | z = -9.7136 | p = 0.000000\n",
      "   → Reject RW3 at this horizon.\n",
      "\n",
      "================================================\n",
      "\n",
      "\n",
      "================================================\n",
      " RW3 TESTS – Weekly returns\n",
      "================================================\n",
      "Observations: 1871\n",
      "\n",
      "--- Autocorrelations (first 10 lags) ---\n",
      "ACF lag  1: -0.0197\n",
      "ACF lag  2: 0.0479\n",
      "ACF lag  3: 0.0121\n",
      "ACF lag  4: -0.0224\n",
      "ACF lag  5: 0.0282\n",
      "ACF lag  6: 0.0512\n",
      "ACF lag  7: -0.0675\n",
      "ACF lag  8: 0.0048\n",
      "ACF lag  9: -0.0210\n",
      "ACF lag 10: 0.0165\n",
      "\n",
      "--- Ljung–Box Q Test (joint autocorrelation) ---\n",
      "Ljung–Box Q(10) = 22.5819, p-value = 0.012400\n",
      "→ Reject RW3: returns show autocorrelation.\n",
      "\n",
      "--- Variance Ratio Tests (Lo–MacKinlay) ---\n",
      "VR(2) = 0.9803 | z = -0.8527 | p = 0.393822\n",
      "   → Cannot reject RW3.\n",
      "VR(5) = 1.0263 | z = 1.0396 | p = 0.298532\n",
      "   → Cannot reject RW3.\n",
      "VR(10) = 1.0595 | z = 2.2862 | p = 0.022241\n",
      "   → Reject RW3 at this horizon.\n",
      "\n",
      "================================================\n",
      "\n",
      "\n",
      "================================================\n",
      " RW3 TESTS – Monthly returns\n",
      "================================================\n",
      "Observations: 430\n",
      "\n",
      "--- Autocorrelations (first 10 lags) ---\n",
      "ACF lag  1: 0.0730\n",
      "ACF lag  2: -0.0127\n",
      "ACF lag  3: 0.0022\n",
      "ACF lag  4: -0.0060\n",
      "ACF lag  5: -0.0295\n",
      "ACF lag  6: 0.0298\n",
      "ACF lag  7: 0.0589\n",
      "ACF lag  8: 0.0296\n",
      "ACF lag  9: -0.0131\n",
      "ACF lag 10: 0.0805\n",
      "\n",
      "--- Ljung–Box Q Test (joint autocorrelation) ---\n",
      "Ljung–Box Q(10) = 8.0174, p-value = 0.627139\n",
      "→ Cannot reject RW3: returns look like white noise.\n",
      "\n",
      "--- Variance Ratio Tests (Lo–MacKinlay) ---\n",
      "VR(2) = 1.0742 | z = 1.5380 | p = 0.124048\n",
      "   → Cannot reject RW3.\n",
      "VR(5) = 1.1100 | z = 2.0818 | p = 0.037359\n",
      "   → Reject RW3 at this horizon.\n",
      "VR(10) = 1.1523 | z = 2.8056 | p = 0.005023\n",
      "   → Reject RW3 at this horizon.\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# RW3 TESTS: Autocorrelation, Ljung-Box Q, Variance Ratio\n",
    "\n",
    "\n",
    "def variance_ratio_test(r, q=2):\n",
    "    \"\"\"\n",
    "    Computes the Lo–MacKinlay Variance Ratio VR(q).\n",
    "    Under RW3, VR(q) = 1.\n",
    "    \"\"\"\n",
    "    r = r.dropna().values\n",
    "    T = len(r)\n",
    "    mu = np.mean(r)\n",
    "\n",
    "    # Variance of 1-step returns\n",
    "    var_1 = np.sum((r - mu)**2) / (T - 1)\n",
    "\n",
    "    # Variance of q-step aggregated returns\n",
    "    r_q = pd.Series(r).rolling(q).sum().dropna().values\n",
    "    var_q = np.sum((r_q - np.mean(r_q))**2) / (len(r_q) - 1)\n",
    "\n",
    "    VR = var_q / (q * var_1)\n",
    "    \n",
    "    # Asymptotic test statistic (homoscedastic case)\n",
    "    z_stat = (VR - 1) / np.sqrt(2 * (2*q - 1) / (3*q*T))\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
    "\n",
    "    return VR, z_stat, p_value\n",
    "\n",
    "\n",
    "def rw3_tests(return_series, name=\"\", lags_LB=10, VR_list=[2,5,10]):\n",
    "    \"\"\"\n",
    "    Runs all RW3 tests:\n",
    "    1) Autocorrelation checks\n",
    "    2) Ljung–Box Q statistic\n",
    "    3) Variance ratio tests \n",
    "    \"\"\"\n",
    "    r = return_series.dropna()\n",
    "\n",
    "    print(\"\\n================================================\")\n",
    "    print(f\" RW3 TESTS – {name}\")\n",
    "    print(\"================================================\")\n",
    "    print(f\"Observations: {len(r)}\")\n",
    "\n",
    "    \n",
    "    # 1. Autocorrelation Function ACF\n",
    "    \n",
    "    print(\"\\n--- Autocorrelations (first 10 lags) ---\")\n",
    "    acf_vals = acf(r, nlags=10, fft=False)\n",
    "    for lag in range(1, 11):\n",
    "        print(f\"ACF lag {lag:2d}: {acf_vals[lag]:.4f}\")\n",
    "\n",
    "    \n",
    "    # 2. Ljung–Box Q-stat for joint autocor\n",
    "  \n",
    "    print(\"\\n--- Ljung–Box Q Test (joint autocorrelation) ---\")\n",
    "    LB = acorr_ljungbox(r, lags=[lags_LB], return_df=True)\n",
    "    Q = LB['lb_stat'].values[0]\n",
    "    pQ = LB['lb_pvalue'].values[0]\n",
    "    print(f\"Ljung–Box Q({lags_LB}) = {Q:.4f}, p-value = {pQ:.6f}\")\n",
    "\n",
    "    if pQ < 0.05:\n",
    "        print(\"→ Reject RW3: returns show autocorrelation.\")\n",
    "    else:\n",
    "        print(\"→ Cannot reject RW3: returns look like white noise.\")\n",
    "\n",
    "   \n",
    "    #3 Variance-Ratio Tests VR(q)\n",
    "  \n",
    "    print(\"\\n--- Variance Ratio Tests (Lo–MacKinlay) ---\")\n",
    "    for q in VR_list:\n",
    "        VR, zstat, pvr = variance_ratio_test(r, q=q)\n",
    "        print(f\"VR({q}) = {VR:.4f} | z = {zstat:.4f} | p = {pvr:.6f}\")\n",
    "        if pvr < 0.05:\n",
    "            print(\"   → Reject RW3 at this horizon.\")\n",
    "        else:\n",
    "            print(\"   → Cannot reject RW3.\")\n",
    "\n",
    "    print(\"\\n================================================\\n\")\n",
    "    \n",
    "rw3_tests(nasdaq_hourly_df[\"Log_Returns\"],  \"Hourly returns\")\n",
    "rw3_tests(nasdaq_daily_df[\"Log_Returns\"],   \"Daily returns\")\n",
    "rw3_tests(nasdaq_weekly_df[\"Log_Returns\"],  \"Weekly returns\")\n",
    "rw3_tests(nasdaq_monthly_df[\"Log_Returns\"], \"Monthly returns\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
